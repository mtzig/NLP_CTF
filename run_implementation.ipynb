{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from process_data import get_jigsaw_datasets, init_embed_lookup, get_ctf_datasets, get_CivilComments_Datasets, get_jigsaw_dev_data, get_CivilComments_idents_Datasets\n",
    "from models import CNNClassifier\n",
    "from train_eval import train, evaluate, CTF\n",
    "from loss import CLP_loss, ERM_loss\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only run the below code if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: could not create work tree dir 'NLP_CTF': Read-only file system\n",
      "[Errno 2] No such file or directory: '/content/NLP_CTF/'\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mtzig/NLP_CTF.git\n",
    "%cd /content/NLP_CTF/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/NLP_CTF/data'\n",
      "/\n",
      "GoogleNews-vectors-negative300.bin: Read-only file system\n",
      "[Errno 2] No such file or directory: './civil_comments'\n",
      "/\n",
      "civil_comments.csv: Read-only file system\n",
      "/\n",
      "/\n"
     ]
    }
   ],
   "source": [
    "%cd /content/NLP_CTF/data\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7\" -O GoogleNews-vectors-negative300.bin && rm -rf /tmp/cookies.txt\n",
    "%cd ./civil_comments\n",
    "!wget wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1pVM0PGHDXrhE4dqQf-offz_Xv8SoPx0X' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1pVM0PGHDXrhE4dqQf-offz_Xv8SoPx0X\" -O civil_comments.csv && rm -rf /tmp/cookies.txt\n",
    "%cd ..\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args, similar to run.py\n",
    "\n",
    "# DEVICE = args.device is the device Pytorch should use (cuda, mps, cpu)\n",
    "# train_method is the method to train the model (baseline, blind, CLP, augment)\n",
    "# lambda represents the lambda in the CLP method\n",
    "# nontoxic determines whether only nontoxic comments will be used (only for CLP)\n",
    "# verbose prints the results\n",
    "# trials is the number of trials to run\n",
    "# epochs is the number of epochs to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Alfred Adult All-in-One Course) Willard A. Palmer, Morton Manus, Amanda Vick Lethco - Adult All-In-One Course_ Lesson-Theory-Technic_ Level 1. 1-Alfred Publishing Co., Inc. (1994).pdf\n",
      "2022+Total+Rewards+Overview+-+Classified (1).pdf\n",
      "2022-08-29 Concussion Summary Report.pdf\n",
      "2022-10-21 11-21.pdf\n",
      "Acceptable+Docs+for+I-9+and+Citizenship+Verification.pdf\n",
      "Bayes_HW_4_Teagan.pdf\n",
      "\u001b[34mCAC\u001b[m\u001b[m/\n",
      "CAC Client Questions Week 2.pdf\n",
      "\u001b[34mCarleton College\u001b[m\u001b[m/\n",
      "Code+of+Ethical+Conduct.pdf\n",
      "Comps_Paper.pdf\n",
      "\u001b[34mConsulting\u001b[m\u001b[m/\n",
      "Corporate+Onboarding+Guide+(AZ+NC+PA).pdf\n",
      "\u001b[34mCover Letter + Resumes\u001b[m\u001b[m/\n",
      "Cracking the Coding Interview - 189 Programming Questions and Solutions (6th Edition) [EnglishOnlineClub.com].pdf\n",
      "Entry+Level+Offer+-+FAQ.doc\n",
      "GoogleNews-vectors-negative300.bin\n",
      "IMG_0528.HEIC\n",
      "\u001b[34mImportant Documents\u001b[m\u001b[m/\n",
      "\u001b[34mInstallers\u001b[m\u001b[m/\n",
      "JOHNSON Teagan Summer 2022 Poster.pdf\n",
      "Johnson_Teagan_Asana_Cover_Letter.pdf\n",
      "Johnson_Teagan_Fast_Cover_Letter.pdf\n",
      "Johnson_Teagan_Fortinet_Cover_Letter.pdf\n",
      "Johnson_Teagan_HPE_Cover_Letter.pdf\n",
      "Johnson_Teagan_MongoDB_Cover_Letter.pdf\n",
      "Johnson_Teagan_Old_Mission_Cover_Letter (1).pdf\n",
      "Johnson_Teagan_Resume.pdf\n",
      "Johnson_Teagan_Sprout_Cover_Letter.pdf\n",
      "Johnson_Teagan_Transcript.pdf\n",
      "Johnson_Teagan_Vanta_Cover_Letter.pdf\n",
      "Johnson_Teagan_Viasat_Cover_Letter.pdf\n",
      "\u001b[34mLeague History\u001b[m\u001b[m/\n",
      "Maxwell_Comps_Final.pdf\n",
      "\u001b[34mNLP_CTF\u001b[m\u001b[m/\n",
      "Offer Letter_ Teagan Johnson - 26081BR.pdf\n",
      "Offer+Letter+-+Standard+2022-09-23 (1).pdf\n",
      "Overview+-+Entry-Level+New+Hire+-+April+2022+(1).pdf\n",
      "\u001b[34mPage_Rank_Implementation_CS_252\u001b[m\u001b[m/\n",
      "\u001b[34mPictures\u001b[m\u001b[m/\n",
      "RECR_Completion.pdf\n",
      "RStudio_ View PDF.pdf\n",
      "\u001b[34mSCA Project\u001b[m\u001b[m/\n",
      "Screen Shot 2022-04-11 at 11.47.38 AM.png\n",
      "Scrum-and-XP-from-the-Trenches-2nd-edition.pdf\n",
      "Sign+On+Bonus+-+Reimbursement+Agreement+12+months (1).pdf\n",
      "\u001b[34mStats_Projects-HW\u001b[m\u001b[m/\n",
      "\u001b[34mSummerCompSci\u001b[m\u001b[m/\n",
      "\u001b[34mSummerResearch\u001b[m\u001b[m/\n",
      "Teeagan_Search_Engine_Poster.pdf\n",
      "USA+Employment+Agreement+2022-10-18.pdf\n",
      "Week 6 Journal.pdf\n",
      "Week 7 Journal.pdf\n",
      "aaron.jpg\n",
      "baseline_experiment.numbers\n",
      "bayes_hw_6.pdf\n",
      "bias_madlibs_89k.csv\n",
      "case_study_1.Rmd\n",
      "case_study_1.pdf\n",
      "civil_comments.csv\n",
      "civil_test_data.numbers\n",
      "civil_train_data_short.numbers\n",
      "crew_member_benefits_guide_2022.pdf\n",
      "\u001b[34mdragon-architect\u001b[m\u001b[m/\n",
      "\u001b[34mdragon-architect-2\u001b[m\u001b[m/\n",
      "\u001b[34meverlaw_interview\u001b[m\u001b[m/\n",
      "johnson_teagan_bayes_hw_7.pdf\n",
      "object-technology-a-managers-guide.pdf\n",
      "\u001b[34mreact_flask\u001b[m\u001b[m/\n",
      "\u001b[31mreadme.Rmd\u001b[m\u001b[m*\n",
      "readme.log\n",
      "readme.tex\n",
      "synthetic_non_toxic_df.csv\n",
      "\u001b[34mteagan-website\u001b[m\u001b[m/\n",
      "train_df_synthetic.csv\n",
      "\u001b[34muntitled folder\u001b[m\u001b[m/\n",
      "/Users/teaganjohnson/Desktop/NLP_CTF\n",
      "GoogleNews-vectors-negative300.bin  \u001b[34mnotebooks\u001b[m\u001b[m/\n",
      "LICENSE                             process_data.py\n",
      "README.md                           \u001b[34mresults\u001b[m\u001b[m/\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m/                        run.py\n",
      "civil_comments.csv                  run_implementation.ipynb\n",
      "\u001b[34mdata\u001b[m\u001b[m/                               run_more.py\n",
      "loss.py                             \u001b[34mscripts\u001b[m\u001b[m/\n",
      "models.py                           train_eval.py\n"
     ]
    }
   ],
   "source": [
    "%cd Users/teaganjohnson/Desktop/NLP_CTF/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_method = \"baseline\"\n",
    "DEVICE = 'cpu'\n",
    "lmbda = 1\n",
    "nontoxic = True\n",
    "verbose = 1\n",
    "trials = 3\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically pulls embeddings from GoogleNews file in repo\n",
    "embed_lookup = init_embed_lookup()\n",
    "pretrained_embed = torch.from_numpy(embed_lookup.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just gets the training data from jigsaw (used to train the model)\n",
    "# can specify if we want the CLP trained data or not (CLP returns adversarial examples)\n",
    "def get_training_data():\n",
    "    if train_method == 'CLP':\n",
    "        train_data, A = get_jigsaw_datasets(device=DEVICE, data_type='CLP', embed_lookup=embed_lookup)\n",
    "    else:\n",
    "        train_data = get_jigsaw_datasets(device=DEVICE, data_type=train_method, embed_lookup=embed_lookup)\n",
    "\n",
    "    jig_dev_data = get_jigsaw_dev_data(device=DEVICE, embed_lookup=embed_lookup) # what is the dev split?\n",
    "    \n",
    "    return train_data, jig_dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_civil_info():\n",
    "    # get the civil comments data set, acts as test data set\n",
    "    cc_data = get_CivilComments_Datasets(device=DEVICE, embed_lookup=embed_lookup)\n",
    "    # get the identities for civil comments\n",
    "    cc_idents_data = get_CivilComments_idents_Datasets(device=DEVICE, embed_lookup=embed_lookup)\n",
    "    \n",
    "    return cc_data, cc_idents_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 310/310 [00:09<00:00, 31.88it/s]\n",
      "100%|██████████| 531/531 [00:00<00:00, 697.58it/s] \n",
      "100%|██████████| 11683/11683 [00:05<00:00, 2114.19it/s]\n",
      "100%|██████████| 11478/11478 [00:03<00:00, 3356.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# initialize ctf datasets\n",
    "ctf_datas = []\n",
    "for dataset in ('civil_eval', 'civil_train', 'synth_toxic', 'synth_nontoxic'):\n",
    "    ctf_datas.append(get_ctf_datasets(device=DEVICE, dataset=dataset, embed_lookup=embed_lookup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:21<00:00, 7261.28it/s] \n",
      "100%|██████████| 63978/63978 [00:06<00:00, 9687.49it/s] \n",
      "100%|██████████| 133782/133782 [00:11<00:00, 11229.44it/s]\n",
      "100%|██████████| 768/768 [00:00<00:00, 60957.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# load into dataloader\n",
    "# data loader prepares data?\n",
    "\n",
    "train_data, jig_dev_data = get_training_data()\n",
    "\n",
    "cc_data, cc_idents_data = get_civil_info()\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64) # train data set\n",
    "jig_loader = DataLoader(jig_dev_data, batch_size=64) # dev split jigsaw training data\n",
    "\n",
    "cc_loader = DataLoader(cc_data, batch_size=64) # civil comments data\n",
    "cc_idents_loader = DataLoader(cc_idents_data, batch_size=64) # civil comments identities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# just create list of the 4 data loaders above\n",
    "ctf_loaders = []\n",
    "for data in ctf_datas:\n",
    "    ctf_loaders.append(DataLoader(data, batch_size=64))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Trial 1/3=====================\n",
      "initializing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2494 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 338/2494 [02:52<18:21,  1.96it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-b8d590aaa0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}/{int(epochs)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluating model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/NLP_CTF/train_eval.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, verbose)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for trial in range(int(trials)):\n",
    "    print('{:=^50}'.format(f'Trial {trial+1}/{int(trials)}'))\n",
    "\n",
    "    print('initializing model')\n",
    "    # first we do garbage collection,\n",
    "    # as torch sometimes does not free model when we reinitialize it\n",
    "    model = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # initialize models    \n",
    "    model = CNNClassifier(pretrained_embed,device=DEVICE)\n",
    "    if train_method == 'CLP':\n",
    "        loss_fn = CLP_loss(torch.nn.CrossEntropyLoss(), A, lmbda=float(lambda_clp), only_nontox=nontoxic)\n",
    "    else:\n",
    "        loss_fn = ERM_loss(torch.nn.CrossEntropyLoss())\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "    print('done')\n",
    "    # train model\n",
    "    for epoch in range(int(epochs)):\n",
    "        print(f'Epoch {epoch+1}/{int(epochs)}')\n",
    "        train(train_loader, model, loss_fn, optimizer, verbose=verbose)\n",
    "\n",
    "    print('evaluating model')\n",
    "    # evaluate loss/accuracy/sensitivity/specificity/AUC on Jigsaw dev set\n",
    "    jig_results = evaluate(jig_loader, model, get_loss=True, verbose=verbose)\n",
    "\n",
    "    # evaluate loss/accuracy/sensitivity/specificity/AUC on civil comments test set\n",
    "    cc_results = evaluate(cc_loader, model, get_loss=True, verbose=verbose)\n",
    "\n",
    "    # evaluate loss/accuracy/sensitivity/specificity/AUC on civil comments idents only test set\n",
    "    cc_idents_results = evaluate(cc_idents_loader, model, get_loss=True, verbose=verbose)\n",
    "\n",
    "    # evaluate CTF gap over every eval dataset\n",
    "    ctf_gaps = []\n",
    "    for ctf_loader in ctf_loaders:\n",
    "        ctf_gaps.append(CTF(ctf_loader, model))\n",
    "\n",
    "    # TODO: evaluate tp, tn on training identity in Civil Comments\n",
    "\n",
    "    results.append(jig_results+cc_results+cc_idents_results+tuple(ctf_gaps))\n",
    "\n",
    "\n",
    "# output results as csv\n",
    "columns = ('jig_loss', 'jig_accuracy', 'jig_tp', 'jig_tn', 'jig_auc',\n",
    "            'cc_loss', 'cc_accuracy', 'cc_tp', 'cc_tn', 'cc_auc',\n",
    "            'cci_loss', 'cci_accuracy', 'cci_tp', 'cci_tn', 'cci_auc',\n",
    "            'ctf_cc_eval', 'ctf_cc_train',\n",
    "            'ctf_synth_toxic', 'ctf_synth_nontoxic',\n",
    "            )\n",
    "\n",
    "print('outputting results to csv')\n",
    "df_results = pd.DataFrame(np.array(results), columns=columns)\n",
    "df_results.to_csv(f'{test_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
