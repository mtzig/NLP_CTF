{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtzig/NLP_CTF/blob/main/notebooks/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpv2yPbX4pp8"
      },
      "source": [
        "### Baseline Toxicity Classifier\n",
        "Thomas Zeng\n",
        "9/27/22"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD---_ei4pp8"
      },
      "source": [
        "## Colab setup\n",
        "\n",
        "This section is only pertinent if the notebook is run in Colab and not on a local machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLVsf9HN5haR"
      },
      "source": [
        "If you're using colab, make sure to run below code to clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCygdiYr4sZb",
        "outputId": "1efd9838-c5ca-4b45-8554-6d8cd65e5c73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP_CTF'...\n",
            "remote: Enumerating objects: 502, done.\u001b[K\n",
            "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 502 (delta 97), reused 111 (delta 44), pack-reused 329\u001b[K\n",
            "Receiving objects: 100% (502/502), 87.01 MiB | 13.32 MiB/s, done.\n",
            "Resolving deltas: 100% (295/295), done.\n",
            "Checking out files: 100% (42/42), done.\n",
            "/content/NLP_CTF\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mtzig/NLP_CTF.git\n",
        "%cd /content/NLP_CTF/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx6dyHemsq6E"
      },
      "source": [
        "Download Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uij1FLaRq8Ob",
        "outputId": "b2831406-5c9c-4dfa-b31a-2ff1bc8d23f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NLP_CTF/data\n",
            "--2022-10-25 19:35:01--  https://docs.google.com/uc?export=download&confirm=t&id=1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7\n",
            "Resolving docs.google.com (docs.google.com)... 142.251.12.138, 142.251.12.139, 142.251.12.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.251.12.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-08-7o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tv4ecg3dmv5oo61qkr79n9193q8uc3s0/1666726500000/15857340408018396550/*/1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7?e=download&uuid=a851da9a-37bb-46e2-b294-7a842f99e159 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-10-25 19:35:02--  https://doc-08-7o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tv4ecg3dmv5oo61qkr79n9193q8uc3s0/1666726500000/15857340408018396550/*/1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7?e=download&uuid=a851da9a-37bb-46e2-b294-7a842f99e159\n",
            "Resolving doc-08-7o-docs.googleusercontent.com (doc-08-7o-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-08-7o-docs.googleusercontent.com (doc-08-7o-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3644258522 (3.4G) [application/macbinary]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   3.39G  59.6MB/s    in 65s     \n",
            "\n",
            "2022-10-25 19:36:09 (53.2 MB/s) - ‘GoogleNews-vectors-negative300.bin’ saved [3644258522/3644258522]\n",
            "\n",
            "/content/NLP_CTF\n"
          ]
        }
      ],
      "source": [
        "%cd ./data\n",
        "# !wget -O 'GoogleNews-vectors-negative300.bin.gz' 'https://drive.google.com/u/0/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download&confirm=t&uuid=e1f49911-ab4d-44ba-af00-f6733ccabb98'\n",
        "# !gzip -d 'GoogleNews-vectors-negative300.bin.gz'\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1JXm1N6SHmzIawgH7Aa4Ag-ZVuqLX7ba7\" -O GoogleNews-vectors-negative300.bin && rm -rf /tmp/cookies.txt\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8VF2PxN6OM-"
      },
      "source": [
        "Colab does not have the Python library `transformers` (which I use in below code) automatically installed, so we meed to manually install when we start up instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVZwKqJ5q3D5"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade gensim\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSKuhXzx57uc"
      },
      "source": [
        "## Notebook Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3YIa35bp4pp8"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky_7qENDZnY6",
        "outputId": "ce792f58-c783-4131-9680-df08d98e4081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/tzeng/repos/NLP_CTF\n"
          ]
        }
      ],
      "source": [
        "# %cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7gDdHfxMZnY6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from process_data import get_jigsaw_datasets, init_embed_lookup, get_ctf_datasets, get_CivilComments_Datasets\n",
        "from models import CNNClassifier\n",
        "from train_eval import train, evaluate, CTF, get_pred\n",
        "from torch.utils.data import DataLoader\n",
        "from loss import CLP_loss, ERM_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5k7OLXS4ZnY6",
        "outputId": "bc54aa18-f591-4281-bb50-9bf46b57e7e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Using GPU')\n",
        "    DEVICE = torch.device('cuda')\n",
        "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
        "    # macbooks can use metal if the right version of pytorch is installed\n",
        "    print('Using Metal')\n",
        "    DEVICE = torch.device('mps')\n",
        "else:\n",
        "    print('Using cpu')\n",
        "    DEVICE = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CewFs_b84pp9"
      },
      "source": [
        "## Data Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg_HhJyT4pp9"
      },
      "source": [
        "Pytorch requires its datasets to be ascessible following the [datasets api](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files).\n",
        "\n",
        "Below I wrote a simple function to load in the [Jigsaw Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) that the paper [Counterfactual Fairness in\n",
        "Text Classification through Robustness](https://dl.acm.org/doi/pdf/10.1145/3306618.3317950) used to train its toxicity classifier.\n",
        "\n",
        "I use only a very small subset of the available data here for demonstration purposes. Specificaly 256 comments (128 toxic and 128 nontoxic) sampled randomly for the train set and test set respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "g-50dF45ZnY7"
      },
      "outputs": [],
      "source": [
        "embed_lookup = init_embed_lookup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vz8b315r4pp-",
        "outputId": "c40c846d-c425-479d-9fce-25b2ffd26cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159571/159571 [00:13<00:00, 12225.80it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = get_jigsaw_datasets(device=DEVICE, data_type='baseline', embed_lookup=embed_lookup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S_0KL-84pp-"
      },
      "source": [
        "PyTorch models receive data for training and inference through a dataloader. A dataloader samples from a dataset and returns a batch of samples each time it is called."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ka5Bi4Kj4pp-"
      },
      "outputs": [],
      "source": [
        "train_loader =  torch.utils.data.DataLoader(train_data, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNm5htHo4pp-"
      },
      "source": [
        "## Model and Training Stuff Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DLBsb2OXq3D6"
      },
      "outputs": [],
      "source": [
        "pretrained_embed = torch.from_numpy(embed_lookup.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jK6qZ1854pp-"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = CNNClassifier(pretrained_embed,device=DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaQxgG1g4pp-"
      },
      "source": [
        "An epoch is the number of times you go through your datase during training. That is you have trained for 1 epoch when you have seen every sample in your training dataset once.<br>\n",
        "The loss function is the training objective we want our model to minimize.<br>\n",
        "The optimizer is used at every time step i.e. everyime we compute the loss and its gradient. It is used to update the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HbLvNOKd4pp-"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "loss_fn = ERM_loss(torch.nn.CrossEntropyLoss())\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ce6OPZb4pp-"
      },
      "source": [
        "## Train and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrcbly74pp-"
      },
      "source": [
        "For traing, we train for 10 epochs. <br>\n",
        "In general, you should (or more specifically are required to) train and evaluate using different datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Jg1pkhd4pp-",
        "outputId": "f1a4cc28-af8b-43dc-dacb-4207c95e59e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:38<00:00, 64.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.12558598912813207\n",
            "Epoch 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:32<00:00, 76.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.10657821136206365\n",
            "Epoch 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:33<00:00, 74.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.09713671822026193\n",
            "Epoch 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:33<00:00, 74.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.09003182570412666\n",
            "Epoch 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2494/2494 [00:33<00:00, 73.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training loss: 0.08173915485940342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch+1}/{epochs}')\n",
        "    train(train_loader, model, loss_fn, optimizer, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXIHJ9_9RSUI"
      },
      "source": [
        "We first evaluate our results on our train data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_pred('f', model, embed_lookup=embed_lookup)"
      ],
      "metadata": {
        "id": "AwBv4FFnpKAm",
        "outputId": "20c19a6d-9e3b-42dc-bad0-a8ade50a935f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.24295976758003235, -0.11695495247840881], 0.410980224609375)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "3b5da4dccc5d959110f70bd428b51197bb0688003461a0e87be372a9c01e32ac"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}