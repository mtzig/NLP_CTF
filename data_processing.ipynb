{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/jigsaw/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/jigsaw/test.csv\")\n",
    "test_labels_df = pd.read_csv(\"./data/jigsaw/test_labels.csv\")\n",
    "identities = pd.read_csv(\"./data/adjectives_people.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df, test_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159566      0  \n",
       "159567      0  \n",
       "159568      0  \n",
       "159569      0  \n",
       "159570      0  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_short = train_df.drop(train_df.columns[3:8], axis=1)\n",
    "train_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_short = test_df.drop(test_df.columns[3:8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_array = identities.to_numpy()\n",
    "identity_array = np.append(identity_array, 'lesbian')\n",
    "identity_list = identity_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['african american',\n",
       " 'middle aged',\n",
       " 'middle eastern',\n",
       " 'asian',\n",
       " 'sikh',\n",
       " 'latinx',\n",
       " 'japanese',\n",
       " 'black',\n",
       " 'homosexual',\n",
       " 'mexican',\n",
       " 'catholic',\n",
       " 'paralyzed',\n",
       " 'white',\n",
       " 'bisexual',\n",
       " 'chinese']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_list.remove('african american')\n",
    "identity_list.remove('middle aged')\n",
    "identity_list.remove('middle eastern')\n",
    "eval_ids = []\n",
    "eval_ids.append('african american')\n",
    "eval_ids.append('middle aged')\n",
    "eval_ids.append('middle eastern')\n",
    "for i in range(12):\n",
    "    rand_num = random.randint(0,len(identity_list))\n",
    "    ident = identity_list.pop(rand_num)\n",
    "    eval_ids.append(ident)\n",
    "    \n",
    "len(identity_list)\n",
    "eval_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train_identities.txt\", \"w\") as output:\n",
    "    for i in identity_list:\n",
    "        output.write(str(i) + \"\\n\")\n",
    "    \n",
    "with open(\"./data/test_identities.txt\", \"w\") as output:\n",
    "    for i in eval_ids:\n",
    "        output.write(str(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571it [01:10, 2265.54it/s]\n"
     ]
    }
   ],
   "source": [
    "for row_index, row in tqdm(enumerate(train_df_short.itertuples())):\n",
    "    for index, identity in enumerate(identity_list):\n",
    "        if identity in row[2]:\n",
    "            train_df_short.at[row_index, identity] = 1\n",
    "        else:\n",
    "            train_df_short.at[row_index, identity] = 0\n",
    "#print(train_df_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153164it [01:04, 2357.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# test df add 1s and 0s\n",
    "for row_index, row in tqdm(enumerate(test_df_short.itertuples())):\n",
    "    for index, identity in enumerate(identity_list):\n",
    "        if identity in row[2]:\n",
    "            test_df_short.at[row_index, identity] = 1\n",
    "        else:\n",
    "            test_df_short.at[row_index, identity] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_short.to_csv(Path(\"./data/test_df.csv\"))\n",
    "train_df_short.to_csv(Path(\"./data/train_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_short = pd.read_csv(\"./data/test_df_short.csv\")\n",
    "train_df_short = pd.read_csv(\"./data/train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data set:\n",
    "# id - sentence - toxic - 50 cols with 0 if identity is not there, 1 if identity is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_identities_raw = pd.read_csv(\"./data/train_identities.txt\")\n",
    "test_identities = pd.read_csv(\"./data/test_identities.txt\")\n",
    "\n",
    "train_identities_listed = train_identities_raw.to_numpy().tolist()\n",
    "\n",
    "train_identities = []\n",
    "for i in train_identities_listed:\n",
    "    train_identities.append(i[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blindness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571it [00:03, 40412.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding identity column to train_df_short (either works I think)\n",
    "for row_index, row in tqdm(enumerate(train_df_short.itertuples())):\n",
    "    train_df_short.at[row_index, \"identity\"] = 0\n",
    "    for i in range(4,54):\n",
    "        if row[i] == 1:\n",
    "            train_df_short.at[row_index, \"identity\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159571/159571 [00:25<00:00, 6239.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding identity column to train_df_short (either works I think)\n",
    "for row_index in tqdm(range(len(train_df_short))):\n",
    "    train_df_short.at[row_index, \"identity\"] = max([train_df_short.at[row_index, identity] for identity in train_identities])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train_df_blind by dropping all identiy columns from train_df_short\n",
    "train_df_blind = train_df_short.drop(columns = train_identities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159571/159571 [00:03<00:00, 42759.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replacing identities in comment text with an identity token\n",
    "token = \"identity\"\n",
    "for row_index in tqdm(range(len(train_df_blind))):\n",
    "    if train_df_short.at[row_index, \"identity\"] == 1:\n",
    "        for identity in train_identities:\n",
    "            if train_df_short.at[row_index, identity] == 1 :\n",
    "                train_df_blind.at[row_index, \"comment_text\"] = train_df_blind.at[row_index, \"comment_text\"].replace(identity, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blind.to_csv(Path(\"./data/train_df_blind.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_identities = train_df_short[train_df_short.identity==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_identities = train_df_identities.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13947/13947 [00:04<00:00, 3417.72it/s]\n"
     ]
    }
   ],
   "source": [
    "comment_list = []\n",
    "toxic_list = []\n",
    "augmented = []\n",
    "\n",
    "for row_index in tqdm(range(len(train_df_identities))):\n",
    "    for identity in train_identities:\n",
    "        if train_df_identities.at[row_index, identity] == 1:\n",
    "            ind = train_identities.index(identity)\n",
    "            comment_list.append(train_df_identities.at[row_index, \"comment_text\"])\n",
    "            toxic_list.append(train_df_identities.at[row_index, \"toxic\"])\n",
    "            augmented.append(0)\n",
    "            for diff_identity in train_identities[-ind]:\n",
    "                comment_list.append(train_df_identities.at[row_index, \"comment_text\"].replace(identity, diff_identity))\n",
    "                toxic_list.append(train_df_identities.at[row_index, \"toxic\"])\n",
    "                augmented.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135544</th>\n",
       "      <td>\"\\n Auto guides and the motoring press are not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135545</th>\n",
       "      <td>\"\\n Auto guides and the motoring press are not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135546</th>\n",
       "      <td>\"\\n Auto guides and the motoring press are not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135547</th>\n",
       "      <td>\"\\n Auto guides and the motoring press are not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135548</th>\n",
       "      <td>\"\\n Auto guides and the motoring press are not...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135549 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  augmented\n",
       "0       \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0          0\n",
       "1       \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0          1\n",
       "2       \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0          1\n",
       "3       \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0          1\n",
       "4       \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0          1\n",
       "...                                                   ...    ...        ...\n",
       "135544  \"\\n Auto guides and the motoring press are not...      0          1\n",
       "135545  \"\\n Auto guides and the motoring press are not...      0          1\n",
       "135546  \"\\n Auto guides and the motoring press are not...      0          1\n",
       "135547  \"\\n Auto guides and the motoring press are not...      0          1\n",
       "135548  \"\\n Auto guides and the motoring press are not...      0          1\n",
       "\n",
       "[135549 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tuples = list(zip(comment_list, toxic_list))\n",
    "augmented_data = pd.DataFrame(data_tuples, columns=['comment_text','toxic'])\n",
    "augmented_data['augmented'] = augmented\n",
    "augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-adb5d5c3d89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for row_index in tqdm(range(42,44)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     print(train_df_short.where(train_df_short[row_index] == 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maugmented_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5134\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'rows'"
     ]
    }
   ],
   "source": [
    "#augmented_data = pd.DataFrame().reindex_like(train_df_short)\n",
    "#augmented_data\n",
    "# for row_index in tqdm(range(42,44)):\n",
    "#     print(train_df_short.where(train_df_short[row_index] == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data.to_csv(Path(\"./data/train_df_synthetic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
