{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./data/jigsaw/train.csv\")\n",
    "test_df = pd.read_csv(\"./data/jigsaw/test.csv\")\n",
    "test_labels_df = pd.read_csv(\"./data/jigsaw/test_labels.csv\")\n",
    "identities = pd.read_csv(\"./data/adjectives_people.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test_df, test_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "0       0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1       000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2       000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3       0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "...                  ...                                                ...   \n",
       "159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n",
       "159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n",
       "159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "        toxic  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "159566      0  \n",
       "159567      0  \n",
       "159568      0  \n",
       "159569      0  \n",
       "159570      0  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_short = train_df.drop(train_df.columns[3:8], axis=1)\n",
    "train_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_short = test_df.drop(test_df.columns[3:8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gay',\n",
       " 'bisexual',\n",
       " 'transgender',\n",
       " 'trans',\n",
       " 'queer',\n",
       " 'lgbt',\n",
       " 'lgbtq',\n",
       " 'homosexual',\n",
       " 'straight',\n",
       " 'heterosexual',\n",
       " 'male',\n",
       " 'female',\n",
       " 'nonbinary',\n",
       " 'african',\n",
       " 'african american',\n",
       " 'black',\n",
       " 'white',\n",
       " 'european',\n",
       " 'hispanic',\n",
       " 'latino',\n",
       " 'latina',\n",
       " 'latinx',\n",
       " 'mexican',\n",
       " 'canadian',\n",
       " 'american',\n",
       " 'asian',\n",
       " 'indian',\n",
       " 'middle eastern',\n",
       " 'chinese',\n",
       " 'japanese',\n",
       " 'christian',\n",
       " 'muslim',\n",
       " 'jewish',\n",
       " 'buddhist',\n",
       " 'catholic',\n",
       " 'protestant',\n",
       " 'sikh',\n",
       " 'taoist',\n",
       " 'old',\n",
       " 'older',\n",
       " 'young',\n",
       " 'younger',\n",
       " 'teenage',\n",
       " 'millenial',\n",
       " 'middle aged',\n",
       " 'elderly',\n",
       " 'blind',\n",
       " 'deaf',\n",
       " 'paralyzed',\n",
       " 'lesbian']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_array = identities.to_numpy()\n",
    "identity_array = np.append(identity_array, 'lesbian')\n",
    "identity_list = identity_array.tolist()\n",
    "identity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571it [00:49, 3202.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for row_index, row in tqdm(enumerate(train_df_short.itertuples())):\n",
    "    for index, identity in enumerate(identity_list):\n",
    "        if identity in row[2]:\n",
    "            train_df_short.at[row_index, identity] = 1\n",
    "        else:\n",
    "            train_df_short.at[row_index, identity] = 0\n",
    "#print(train_df_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153164it [00:49, 3104.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# test df add 1s and 0s\n",
    "for row_index, row in tqdm(enumerate(test_df_short.itertuples())):\n",
    "    for index, identity in enumerate(identity_list):\n",
    "        if identity in row[2]:\n",
    "            test_df_short.at[row_index, identity] = 1\n",
    "        else:\n",
    "            test_df_short.at[row_index, identity] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>gay</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>transgender</th>\n",
       "      <th>trans</th>\n",
       "      <th>queer</th>\n",
       "      <th>lgbt</th>\n",
       "      <th>lgbtq</th>\n",
       "      <th>...</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>teenage</th>\n",
       "      <th>millenial</th>\n",
       "      <th>middle aged</th>\n",
       "      <th>elderly</th>\n",
       "      <th>blind</th>\n",
       "      <th>deaf</th>\n",
       "      <th>paralyzed</th>\n",
       "      <th>lesbian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>\"::: Somebody will invariably try to add Relig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>\" \\n\\n It says it right there that it IS a typ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>\" \\n\\n == Before adding a new product to the l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>:Jerome, I see you never got around to this…! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>==Lucky bastard== \\n http://wikimediafoundatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>==shame on you all!!!== \\n\\n You want to speak...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>\" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63978 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "5       0001ea8717f6de06  Thank you for understanding. I think very high...   \n",
       "7       000247e83dcc1211                   :Dear god this site is horrible.   \n",
       "11      0002f87b16116a7f  \"::: Somebody will invariably try to add Relig...   \n",
       "13      0003e1cccfd5a40a  \" \\n\\n It says it right there that it IS a typ...   \n",
       "14      00059ace3e3e9a53  \" \\n\\n == Before adding a new product to the l...   \n",
       "...                  ...                                                ...   \n",
       "153150  fff8f64043129fa2  :Jerome, I see you never got around to this…! ...   \n",
       "153151  fff9d70fe0722906  ==Lucky bastard== \\n http://wikimediafoundatio...   \n",
       "153154  fffa8a11c4378854  ==shame on you all!!!== \\n\\n You want to speak...   \n",
       "153155  fffac2a094c8e0e2  MEL GIBSON IS A NAZI BITCH WHO MAKES SHITTY MO...   \n",
       "153156  fffb5451268fb5ba  \" \\n\\n == Unicorn lair discovery == \\n\\n Suppo...   \n",
       "\n",
       "        toxic  gay  bisexual  transgender  trans  queer  lgbt  lgbtq  ...  \\\n",
       "5           0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "7           0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "11          0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "13          0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "14          0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "...       ...  ...       ...          ...    ...    ...   ...    ...  ...   \n",
       "153150      0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "153151      0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "153154      0  1.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "153155      1  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "153156      0  0.0       0.0          0.0    0.0    0.0   0.0    0.0  ...   \n",
       "\n",
       "        young  younger  teenage  millenial  middle aged  elderly  blind  deaf  \\\n",
       "5         0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "7         0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "11        0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "13        0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "14        0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "...       ...      ...      ...        ...          ...      ...    ...   ...   \n",
       "153150    0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "153151    0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "153154    0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "153155    0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "153156    0.0      0.0      0.0        0.0          0.0      0.0    0.0   0.0   \n",
       "\n",
       "        paralyzed  lesbian  \n",
       "5             0.0      0.0  \n",
       "7             0.0      0.0  \n",
       "11            0.0      0.0  \n",
       "13            0.0      0.0  \n",
       "14            0.0      0.0  \n",
       "...           ...      ...  \n",
       "153150        0.0      0.0  \n",
       "153151        0.0      0.0  \n",
       "153154        0.0      0.0  \n",
       "153155        0.0      0.0  \n",
       "153156        0.0      0.0  \n",
       "\n",
       "[63978 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_short = test_df_short[test_df_short[\"toxic\"] != -1]\n",
    "test_df_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "test_df_short.to_csv(Path(\"./data/test_df.csv\"))\n",
    "train_df_short.to_csv(Path(\"./data/train_df.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_short = pd.read_csv(\"./data/test_df_short.csv\")\n",
    "train_df_short = pd.read_csv(\"./data/train_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training data set:\n",
    "# id - sentence - toxic - 50 cols with 0 if identity is not there, 1 if identity is there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blindness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159571it [00:02, 60980.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding identity column to train_df_short (either works I think)\n",
    "for row_index, row in tqdm(enumerate(train_df_short.itertuples())):\n",
    "    train_df_short.at[row_index, \"identity\"] = 0\n",
    "    for i in range(4,54):\n",
    "        if row[i] == 1:\n",
    "            train_df_short.at[row_index, \"identity\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:24<00:00, 6500.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Adding identity column to train_df_short (either works I think)\n",
    "for row_index in tqdm(range(len(train_df_short))):\n",
    "    train_df_short.at[row_index, \"identity\"] = max([train_df_short.at[row_index, identity] for identity in identity_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train_df_blind by dropping all identiy columns from train_df_short\n",
    "train_df_blind = train_df_short.drop(columns = identity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:03<00:00, 47562.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Replacing identities in comment text with an identity token\n",
    "token = \"identity\"\n",
    "for row_index in tqdm(range(len(train_df_blind))):\n",
    "    if train_df_short.at[row_index, \"identity\"] == 1:\n",
    "        for identity in identity_list:\n",
    "            if train_df_short.at[row_index, identity] == 1 :\n",
    "                train_df_blind.at[row_index, \"comment_text\"] = train_df_blind.at[row_index, \"comment_text\"].replace(identity, token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_blind.to_csv(Path(\"./data/train_df_blind.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6434/159571 [13:32<5:22:27,  7.92it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e2ee6bc00534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdiff_identity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midentity_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mdiff_identity\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                         \u001b[0mtrain_df_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msynth_row_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_short\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                         \u001b[0mtrain_df_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msynth_row_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df_short\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff_identity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0msynth_row_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1698\u001b[0m                 \u001b[0;31m# We are setting multiple columns in a single row.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0milocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_null_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   1799\u001b[0m         \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplane_indexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1801\u001b[0;31m         \u001b[0mser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1803\u001b[0m         \u001b[0;31m# perform the equivalent of a setitem on the info axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   2962\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2964\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2965\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_col_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36miget\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \"\"\"\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mblknos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;31m# Note: these can be altered by other BlockManager methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df_synthetic = pd.DataFrame().reindex_like(train_df_short)\n",
    "synth_row_index = 0\n",
    "for row_index in tqdm(range(len(train_df_blind))):\n",
    "    if train_df_blind.at[row_index, \"identity\"] == 1:\n",
    "        for identity in identity_list:\n",
    "            if train_df_short.at[row_index, identity] == 1:\n",
    "                for diff_identity in identity_list:\n",
    "                    if diff_identity != identity:\n",
    "                        train_df_synthetic.loc[synth_row_index] = train_df_short.loc[row_index]\n",
    "                        train_df_synthetic.at[synth_row_index, \"comment_text\"] = train_df_short.at[row_index, \"comment_text\"].replace(identity, diff_identity)\n",
    "                        synth_row_index += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                id  \\\n",
      "0               0  0000997932d777bf   \n",
      "1               1  000103f0d9cfb60f   \n",
      "2               2  000113f07ec002fd   \n",
      "3               3  0001b41b1c6bb37e   \n",
      "4               4  0001d958c54c6e35   \n",
      "...           ...               ...   \n",
      "159566     159566  ffe987279560d7ff   \n",
      "159567     159567  ffea4adeee384e90   \n",
      "159568     159568  ffee36eab5c267c9   \n",
      "159569     159569  fff125370e4aaaf3   \n",
      "159570     159570  fff46fc426af1f9a   \n",
      "\n",
      "                                             comment_text toxic  gay bisexual  \\\n",
      "0       Explanation\\nWhy the edits made under my usern...     0  0.0      0.0   \n",
      "1       D'aww! He matches this background colour I'm s...     0  0.0      0.0   \n",
      "2       Hey man, I'm really not trying to edit war. It...     0  0.0      0.0   \n",
      "3       \"\\nMore\\nI can't make any real suggestions on ...     0  0.0      0.0   \n",
      "4       You, sir, are my hero. Any chance you remember...     0  0.0      0.0   \n",
      "...                                                   ...   ...  ...      ...   \n",
      "159566  \":::::And for the second time of asking, when ...     0  0.0      0.0   \n",
      "159567  You should be ashamed of yourself \\n\\nThat is ...     0  0.0      0.0   \n",
      "159568  Spitzer \\n\\nUmm, theres no actual article for ...     0  0.0      0.0   \n",
      "159569  And it looks like it was actually you who put ...     0  0.0      0.0   \n",
      "159570  \"\\nAnd ... I really don't think you understand...     0  0.0      0.0   \n",
      "\n",
      "       transgender trans queer lgbt  ... younger teenage millenial  \\\n",
      "0              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "1              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "2              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "3              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "4              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "...            ...   ...   ...  ...  ...     ...     ...       ...   \n",
      "159566         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159567         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159568         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159569         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159570         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "\n",
      "       middle aged elderly blind deaf paralyzed lesbian identity  \n",
      "0              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "1              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "2              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "3              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "4              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "...            ...     ...   ...  ...       ...     ...      ...  \n",
      "159566         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159567         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159568         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159569         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159570         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "\n",
      "[159571 rows x 55 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                id  \\\n",
      "0               0  0000997932d777bf   \n",
      "1               1  000103f0d9cfb60f   \n",
      "2               2  000113f07ec002fd   \n",
      "3               3  0001b41b1c6bb37e   \n",
      "4               4  0001d958c54c6e35   \n",
      "...           ...               ...   \n",
      "159566     159566  ffe987279560d7ff   \n",
      "159567     159567  ffea4adeee384e90   \n",
      "159568     159568  ffee36eab5c267c9   \n",
      "159569     159569  fff125370e4aaaf3   \n",
      "159570     159570  fff46fc426af1f9a   \n",
      "\n",
      "                                             comment_text toxic  gay bisexual  \\\n",
      "0       Explanation\\nWhy the edits made under my usern...     0  0.0      0.0   \n",
      "1       D'aww! He matches this background colour I'm s...     0  0.0      0.0   \n",
      "2       Hey man, I'm really not trying to edit war. It...     0  0.0      0.0   \n",
      "3       \"\\nMore\\nI can't make any real suggestions on ...     0  0.0      0.0   \n",
      "4       You, sir, are my hero. Any chance you remember...     0  0.0      0.0   \n",
      "...                                                   ...   ...  ...      ...   \n",
      "159566  \":::::And for the second time of asking, when ...     0  0.0      0.0   \n",
      "159567  You should be ashamed of yourself \\n\\nThat is ...     0  0.0      0.0   \n",
      "159568  Spitzer \\n\\nUmm, theres no actual article for ...     0  0.0      0.0   \n",
      "159569  And it looks like it was actually you who put ...     0  0.0      0.0   \n",
      "159570  \"\\nAnd ... I really don't think you understand...     0  0.0      0.0   \n",
      "\n",
      "       transgender trans queer lgbt  ... younger teenage millenial  \\\n",
      "0              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "1              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "2              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "3              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "4              0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "...            ...   ...   ...  ...  ...     ...     ...       ...   \n",
      "159566         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159567         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159568         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159569         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "159570         0.0   0.0   0.0  0.0  ...     0.0     0.0       0.0   \n",
      "\n",
      "       middle aged elderly blind deaf paralyzed lesbian identity  \n",
      "0              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "1              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "2              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "3              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "4              0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "...            ...     ...   ...  ...       ...     ...      ...  \n",
      "159566         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159567         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159568         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159569         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "159570         0.0     0.0   0.0  0.0       0.0     0.0      0.0  \n",
      "\n",
      "[159571 rows x 55 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_synthetic = pd.DataFrame().reindex_like(train_df_short)\n",
    "synth_row_index = 0\n",
    "for row_index in tqdm(range(42,44)):\n",
    "    for identity in identity_list:\n",
    "        print(train_df_short.where(train_df_short[identity] == 0, comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "train_df_synthetic.to_csv(Path(\"./data/train_df_synthetic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
