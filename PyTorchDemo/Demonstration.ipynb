{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mtzig/NLP_CTF/blob/main/PyTorchDemo/Demonstration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpv2yPbX4pp8"
   },
   "source": [
    "### A Demonstration of Training and Evaluating A Toxicity Classifier\n",
    "Thomas Zeng\n",
    "9/20/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KD---_ei4pp8"
   },
   "source": [
    "## Colab setup\n",
    "\n",
    "This section is only pertinent if the notebook is run in Colab and not on a local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLVsf9HN5haR"
   },
   "source": [
    "If you're using colab, make sure to run below code to clone the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FCygdiYr4sZb",
    "outputId": "f9d16173-70f6-4390-f373-751b55ed0307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'NLP_CTF' already exists and is not an empty directory.\n",
      "/content/NLP_CTF/PyTorchDemo\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/mtzig/NLP_CTF.git\n",
    "%cd /content/NLP_CTF/PyTorchDemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dIAAw7u5nqb"
   },
   "source": [
    "If you are on colab and using a gpu instance, below command will show the GPU google allocated to this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6U5Evsgp5JYr",
    "outputId": "493b2e46-5fc9-41cd-9ec8-4f20048560ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 21 04:14:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8VF2PxN6OM-"
   },
   "source": [
    "Colab does not have the Python library `transformers` (which I use in below code) automatically installed, so we meed to manually install when we start up instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRtyZ4MO6Eu6",
    "outputId": "4739f7af-b8b5-4636-b7e6-f887d9ff079d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSKuhXzx57uc"
   },
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZ207yT_4pp8"
   },
   "source": [
    "Autoreload extension is used so that everyime you modify python files imported by notebook, you don't have to restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3YIa35bp4pp8"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N6E9ljgj4pp9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DL/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import load_jigsaw\n",
    "from dataloaders import InfiniteDataLoader\n",
    "from models import BertClassifier\n",
    "from train_eval import train, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8jIIK3Bf4pp9"
   },
   "source": [
    "Pytorch can do it's computation in three modes.\n",
    "\n",
    "1. Cuda: if you have a Nvidia gpu and you have a version of PyTorch installed that has cuda enabled (fastest speed)\n",
    "2. Metal: if you have an Apple device with Apple Silicon (M1 or M2) -- this implementation of PyTorch is new, not feature complete and rather buggy (medium speed)\n",
    "3. CPU: this is just the cpu (slowest speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kL__ImTD4pp9",
    "outputId": "8eda552a-b29d-4cd6-ac25-aae94f459dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Metal\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print('Using GPU')\n",
    "    DEVICE = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    # macbooks can use metal if the right version of pytorch is installed\n",
    "    print('Using Metal')\n",
    "    DEVICE = torch.device('mps')\n",
    "else:\n",
    "    print('Using cpu')\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CewFs_b84pp9"
   },
   "source": [
    "## Data Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cg_HhJyT4pp9"
   },
   "source": [
    "Pytorch requires its datasets to be ascessible following the [datasets api](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files).\n",
    "\n",
    "Below I wrote a simple function to load in the [Jigsaw Dataset](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) that the paper [Counterfactual Fairness in\n",
    "Text Classification through Robustness](https://dl.acm.org/doi/pdf/10.1145/3306618.3317950) used to train its toxicity classifier.\n",
    "\n",
    "I use only a very small subset of the available data here for demonstration purposes. Specificaly 256 comments (128 toxic and 128 nontoxic) sampled randomly for the train set and test set respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vz8b315r4pp-",
    "outputId": "967ade6f-56d5-4c6b-bbec-230326e7c25a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:00<00:00, 1537.61it/s]\n",
      "100%|██████████| 256/256 [00:00<00:00, 1599.17it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_jigsaw(device=DEVICE, demo_mode=True) #demo_mode=True only loads a subset of entire dataset so as to make training faster for demonstration purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqJeMd2PTmIE"
   },
   "source": [
    "In Colab and Jupyter notebook, you can view the source of a function using `??`. Thus the we can look at the specific implementation of `load_jigsaw` function written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "K9FYcZhtTxML"
   },
   "outputs": [],
   "source": [
    "??load_jigsaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9S_0KL-84pp-"
   },
   "source": [
    "PyTorch models receive data for training and inference through a dataloader. A dataloader samples from a dataset and returns a batch of samples each time it is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ka5Bi4Kj4pp-"
   },
   "outputs": [],
   "source": [
    "train_loader =  InfiniteDataLoader(train_data, batch_size=16)\n",
    "test_loader = InfiniteDataLoader(test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNm5htHo4pp-"
   },
   "source": [
    "## Model and Training Stuff Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbKN0TMY4pp-"
   },
   "source": [
    "For our model, we use transfer learning, i.e. we use a pre-trained model -- DistilBert -- implemented by HuggingFace. Our `BertClassifier` is a simple wrapper arround their model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jK6qZ1854pp-",
    "outputId": "11ef370b-edf1-4b02-f999-7387808a0d76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaQxgG1g4pp-"
   },
   "source": [
    "An epoch is the number of times you go through your datase during training. That is you have trained for 1 epoch when you have seen every sample in your training dataset once.<br>\n",
    "The loss function is the training objective we want our model to minimize.<br>\n",
    "The optimizer is used at every time step i.e. everyime we compute the loss and its gradient. It is used to update the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HbLvNOKd4pp-"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ce6OPZb4pp-"
   },
   "source": [
    "## Train and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qrcbly74pp-"
   },
   "source": [
    "For traing, we train for 10 epochs. <br>\n",
    "In general, you should (or more specifically are required to) train and evaluate using different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Jg1pkhd4pp-",
    "outputId": "c85ba18d-a0b3-4425-a13a-d96d7d8a76f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.6664525307714939\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:27<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.5536530558019876\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:29<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.3635572390630841\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:30<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.20008584856987\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:30<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.12325309030711651\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:35<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.06678666011430323\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:29<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.057261363486759365\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:24<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.026767334318719804\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:22<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.017257232044357806\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average training loss: 0.013622803729958832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    train(train_loader, model, loss_fn, optimizer, verbose=True, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXIHJ9_9RSUI"
   },
   "source": [
    "We first evaluate our results on our train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0MyzVR_RAd0",
    "outputId": "0882640f-c283-4e2b-de56-1243f05a261d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.009806430898606777\n",
      "Accuracy: 1.0, Sensitivity: 1.0, Specificity: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate(train_loader, model, get_loss=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5VWVNHrR6Tn"
   },
   "source": [
    "Our results are pretty amazing at first glance. However this is misleading as we are evaluating on the data we trained the model on. The high accuracies is a clear indication that the model is overfitting. An overfitted model is bad in general -- however in this case it is a clear indication that our code is working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjFQ64q54pp-"
   },
   "source": [
    "If we then evaluate our reults on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9u43Jv2c4pp-",
    "outputId": "a40f2451-be4d-4ed6-8c15-f61e9757202c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:02<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5528503656387329\n",
      "Accuracy: 0.80859375, Sensitivity: 0.8203125, Specificity: 0.796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate(test_loader, model, get_loss=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuPzhPJZ4pp_"
   },
   "source": [
    "Clearly our results are much worse than before. Although they surprising are not that bad considering that we trained on only 256 examples (128 toxic, 128 non-toxic).\n",
    "\n",
    "Although, these metrics do not take into account fairness -- so the model may very well be performing well due to some spurious correlation. Hence our comps project.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b5da4dccc5d959110f70bd428b51197bb0688003461a0e87be372a9c01e32ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
